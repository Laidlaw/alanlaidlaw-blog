---
title: "(Data = Oil)(AI = Fire)"
description: "“AI is the new electricity” — Andrew Ng"
date: "2019-08-05T02:25:55.106Z"
categories: []
published: false
---

![The Door to Hell, from [https://climateviewer.com/2013/10/23/the-door-to-hell-drilling-accident-burning-continuously-for-40-years/](https://climateviewer.com/2013/10/23/the-door-to-hell-drilling-accident-burning-continuously-for-40-years/)](./asset-1.jpeg)

> _“AI is the new_ **_electricity_**_” _— Andrew Ng

> _“AI is the new_ **_fire_**_”_ — Sundar Pichai

> _“Data is the new_ **_oil_**_”_ — Everyone

Have you heard these phrases before? They’ve been getting traction lately. (possibly overtaking Andressen’s encomium “Software is eating the world” by 2019.)

Compared to Elon Musk’s prognostications, these analogies sound populist or even pastoral, while retaining the familiar hint of Manifest Destiny that Silicon Valley is known for.

When I first heard Google’s CEO, say that _“AI is bigger than fire,”_ I flinched a little. He was laying it on a bit thick, but I gave him the benefit of the doubr.

People tend to think of AI as either SkyNet or a dorky chatbot. Consumer-grade AI like Siri, Google Maps, or image recognition aren’t much of a threat, so it’s difficult to see how AI will reshape society. 

Today’s AI just seems like a slightly more engineered experience. Like a healthy alternative to junk food that sometimes [backfire](https://en.wikipedia.org/wiki/Olestra)s. **AI is the new Olestra.**

![_AI is the new_ **_Olestra _**_— me_](./asset-2.jpeg)

Sundar’s analogy suggests that “Fire is dangerous, but it’ll ultimately be a boon for society.” And there’s a subtext that shouldn’t be ignored: Google is the new Prometheus.

Lately, I’ve come to think that these comparisons are dangerous. Here’s why:

---

#### 1\. Mystification and Exoneration

Fire occurs in nature. AI does not. We have a innate reaction to fire: awe at a distance and terror in proximity. AI is still concept. It’s terrifying the way political power is terrifying. By mystifying AI, we surrender some of our agency to change it. We are essentially agreeing that it is unknowable and out of our hands.

By framing AI as fire, we’re saying that early adopters can be exonerated for accidentally burning a few villages. It’s in name of progress, after all. 

The analogy also suggests that we’re all on the same playing field, that we can take advantage of AI equally. I don’t know how we got fire, but I doubt it was evenly-distributed. Imagine how the invention of fire might have played out:

> BREAKING: FIRE INVENTED. Biggest deal since invention of swear words. Fire scares beasts. Fire makes beasts easier to eat. Fire makes beasts taste good. Studies show that cooked beasts lead to better health. Fire also keeps people warm at night, so they die less.

> “We’re not even in the stone age of this emerging **_freaking_** technology,” one cave man said. “Fire dances on the cave walls and tells us stories! No one saw that coming.”

> But in the prairie, it’s a different story. Fire is scarce. The Wind steals Fire. And if the Wind is angry, it spreads Fire everywhere. 

> “I just don’t think the prairie folk are capable of grasping fire the way we do,” said one cave man, CEO. “It’s a shame. Our culture is changing so fast, they probably won’t be able to adapt.”

No doubt, AI is exciting. Advances in GPUs, big data, and clever algorithms, have given us unprecedented access to AI. It feels like the ‘90’s, when the web was the wild west. 

But there is a big difference between a Kaggle competition and applied machine learning. About as different as campfire and an oil refinery. 

---

#### 3\. Data is the new air

A big misconception about AI is that it’s magic comes from a black box algorithm, but it’s far more about the data. Even Alpha Zero, the descendant of Alpha Go and possibly the greatest achievement toward generalized AI, runs on **very pure data**. The game of Go is incredibly complex, but it has three qualities that are ideal for AI: 

1.  The board is essentially a spreadsheet. 
2.  There are clear rules. 
3.  There is an end state with a winner and a loser.

Think of it this way: If AI is fire, then data is air. Air is very stable. But imagine if air was actually a hodgepodge of gases, drifting in undetectable concentrations. A little hydrogen here, a little nitrogen there. Fire could turn into poison or an explosion in an instant. This is a better picture of the current state of data.

At least 70% of a data scientist’s billable hours is spent on cleaning data. “Garbage in, garbage out,” is the data scientist’s lament. 

Data scientists spend all this time discovering, cleaning, and cultivating data so they can find features. Features are what AI models ultimately consume and features have our fingerprints all over them.

#### 4\. Feature Engineering is the new politics

I like to think of features as legislation. Policies have to be reduced to words and those words have to be agreed on. The conversation around the 2nd amendment might be completely different if we knew the spirit of the policy rather than the words. 

Let’s say you speed and get a ticket. Maybe you didn’t see the speed limit because the sign was intentionally obscured. Your speed is a feature, while the sign’s visibility is more difficult to define. You may get lucky if there is a policy around signs, but you’ll probably get stuck with a fine.

I experienced this recently when I liked a tweet from someone that I didn’t recognize. When I researched this person, I found that we held very different beliefs. Now I get ads on YouTube and Amazon about them. That’s my fine.

#### 5\. Data and Lore

Lore, referenced in the tweet above, was a character in Star Trek: The Next Generation. He was the evil twin of Data, a well-intended and naive android. The crew would often mix up the two. Which version of me does Facebook see?

---

#### 6\. Data is the decomposition of life

Data falls off us like skin cells, leaving evidence of us everywhere. Data scientists, like archeologists, sweep up our data points and stitch together jigsawed shadows of ourselves. AI sees us the way we see dinosaurs, reconstructed from fossil remains. 

> “Data is the new oil” implies that we’re the new fossil fuel.

Most of the talk about bias in AI is focused on the current examples of bias in culture. Facial recognition is the most common example. AI can be used to guess your sexual preference or your likelihood to commit a crime. Or deny you a job based on your color.

But there is a deeper bias in AI, that has nothing to do with gender or race. It comes down to what can become a feature. And that has much more to do with the system surrounding a model than any black box. 

---

#### 7\. Stars and Clouds

Stars were probably man’s first data points. When early man looked up in the heavens, they saw the same pattern of lights nearly every night. That point of light was a star’s one feature. They were distant, fixed, and unlike anything else on earth. 

I like to imagine that stars taught us how to think critically. Everything else on earth was so close, so entangled in our senses, that I doubt we would have ever conceived of data without the nightly persistence of stars. 

We were always proto-biologists and metaphysicians, but no other field of study advanced our thinking like astronomy. Copernicus, Kepler, and Galileo laid the foundation of the scientific method by working out how planets moved.

Meanwhile, clouds have been hanging around millions of years. What have clouds ever done, compared to stars? Clouds are so much more diverse than stars, yet they’ve never advanced our thinking. There may have been brilliant scientists who focused on clouds, but we’ve never heard of them. 

It’s because of stars that we’re able to predict the weather. The best we can do with clouds is lump them into fuzzy categories.

AI sees stars, not clouds.

---

AI is Fracking

  

What we talk about when we talk about data

Data Doctors

Oxen and Plow

The Echo Chamber

Most attempts at AI in the enterprise fail. 

It would be better to think of AI in ecological terms, because AI only thrives under certain conditions. 

  

But the most problematic part of “AI is the fire” is that overlooks the infrastructure around the fire. It’s the reason most AI efforts in the enterprise fail. It’s reason AI costs so much to maintain. 

  

  

  

  

  

By comparison, fire runs on auto-pilot. But AI requires a considerable amount of investment. 

Perhaps I’m thinking too narrowly. Perhaps AI taps into the fundamental algorithms of nature, like fire. And perhaps over time, like fire, AI will become much easier to maintain. The algorithms behind deep learning are not new and are not subject to copyright, so this could be a convincing argument.

this is where context is so important. AI works really well if your data is already clean. Clean data happens to come from companies that started on the web. Facebook, Amazon, and Google, all have products that act as their data cleaners. So they reap the rewards, like the cavemen. 

Meanwhile, those out on the prairie fumble around with sparks like kaggle competitions. Even if they make a flame, they can’t then build up an infrastructure to support it.

That’s why I’d like to make a better, or at least more laborious camparsion:

AI = Fracking

  

  

  

  

  

By mystifying AI, we 

  

There’s also the killer robot crowd, but c’mon, Siri, [srsly](https://www.urbandictionary.com/define.php?term=srsly)? 

AI is like that magic oil that makes everything better until…\[link\]

  

  

  

  

It’s like a new baseline is being set for us. 

I didn’t mind it at first because AI is hard to explain. Sometimes I think that 

  

  

When I first heard these phrases, I didn’t mind them. I assumed they were in service of a greater good to educate the public. 

  

I believe Andrew Ng believes that AI is the new electricity. Who couldn’t love that guy?

  

  

At first, I gave them the benefit of the doubt. When Google’s CEO recently claimed that “AI was bigger than fire,” I figured he was 

  

  

I hear them all the time. They ring in my ears along. Same with Musk, Hawking, Putin, and the rest. The message is clear, AI is a big deal. 

  

  

And while their intentions may be pure, this approach is not good for society.

These slogans aren’t helpful. Comparing AI to fire does two things: it mystifies AI and smolders blame. These slogans are frameworks. “AI is so wild and new, things will obviously go wrong at times but, in aggregate, this will be good for mankind.”

That’s bullshit.

Given the recent strife of technolopoly backfires, I think its useful to take part in the analogies we use to frame new technolgies. Sundar and Andrew are probably dead right when it comes to AI. But there’s a long time between their premonition and our reality. And we need better metaphors to expalin aI in the moment til the next election.

  

  

  

What rings in my ears is the source of these slogans. These guys are legit scientists. They aren’t prone to exaggeration, punditry, or hucksterism. Andrew Ng co-founded Coursera, an online service that helps anyone become a data scientist. 

  

  

  

This is not helpful.

Andrew Ng and Sundar Pichai are scientists. They rarely, if ever, make such broad claims. I think they have good intentions. They’re extending themselves to 

  

Data is probably the new oil, given that we’re the new fossil fuel. AI may be the new fire. And all that sounds like a match made in heaven. But I’d like to submit a slightly more grounded comparison:

> Machine learning is the new fracking. 

Fracking is game-changing new technology. It lets oil companies target smaller clusters of oil, rather than the massive reserves. Those are getting harder to find. Basically, at a certain depth underground, horizontal drills spiderweb out to find tiny pockets of shale. If you’ve seen Stranger Things, just imagine the Upside Down World.

Ethical ramifications aside, horizontal drilling is much more elusive than it seems. Peter Zeihan in his book _The Accidental Superpower_ gave the following prediction:

> It is extremely unlikely that the shale technologies will be applied en masse anywhere outside of North America before 2035.

He identifies 4 factors that “must exist simultaneously” for fracking to work. Three of them can easily map to applied machine learning: 

1.  Huge, Deep Capital Markets
2.  Highly Skilled Labor
3.  A̶ ̶L̶e̶g̶a̶l̶ ̶S̶t̶r̶u̶c̶t̶u̶r̶e̶ ̶T̶h̶a̶t̶ ̶R̶e̶w̶a̶r̶d̶s̶ ̶L̶a̶n̶d̶o̶w̶n̶e̶r̶s̶ ̶f̶o̶r̶ ̶T̶h̶e̶i̶r̶ ̶P̶a̶r̶t̶i̶c̶i̶p̶a̶t̶i̶o̶n̶
4.  A Preexisting N̶a̶t̶u̶r̶a̶l̶ ̶G̶a̶s̶ ̶C̶o̶l̶l̶e̶c̶t̶i̶o̶n̶,̶ ̶T̶r̶a̶n̶s̶p̶o̶r̶t̶,̶ ̶a̶n̶d̶ ̶ Distribution Infrastructure

---

#### Huge, Deep Capital Markets

> You have to throw a lot of money at a fracking project to get results. As with everything else about shale, there is no average, but costs can be extreme and typically everything — roads, pipes, drills, and labor sufficiently skilled to drill a mile beneath their feet — has to be paid up front. Rigs — whose rates include labor — rent at anywhere from $10,000 to $100,000 a day. An easy well might “only” take eight days, but difficult wells can be five times that. A low-end figure is usually in the range of $6 million per well.

Applied machine learning is a big risk that requires deep commitment from the enterprise. McKinsey reported that most enterprise ML initiatives fail and its easy to see why. Kaggle competitions and online courses come with clean data, but enterprise data is much dirtier. The state of the data and the corporate structure will dictate how an ML problem gets defined. This took me a long time to understand. There is no MVP in applied ML. 

---

#### Highly Skilled Labor

> Drilling a winding shaft into a complicated, variable-density geology several thousand feet underground in order to inject a pressurized fluid that will precision-crack a rock formation in real time so that the hydrocarbons trapped within are funneled up a well shaft is every bit as hard as it sounds. Moreover, every single well — even two wells on the same drilling pad — is different. This is not a job for the faint of heart or the faint of skill. Each well crew has to know precisely what they are doing and **has to be in command of skills ranging from engineering to geology to chemicals to fluid dynamics**. This is not a task for a handful of state-owned oil thugs who got their jobs as part of a nationalization program, but for people with years of experience who benefit from the trust of their superiors to make adjustments as they go. Each well requires a crew of high-skilled petroleum engineers and support staff able to operate in a variety of environments with minimal supervision.

…Data Scientists. 

(And some folks who can wiggle through the geology of corporate bureaucracy.) Now the big one:

---

#### A Preexisting Distribution Infrastructure

> The final requirement has to do with the nature of the output. Shale wells produce not just oil, but oil and natural gas, and herein lies a problem. Oil is a liquid and so can be trucked, barged, railed, or piped anywhere you want. The multitude of transport options allow shale oil production to be very quickly monetized.

> Natural gas, however, is, well, a gas. It cannot be trucked, barged, or railed efficiently except under extreme pressure, which poses extreme costs for additional equipment and not insignificant safety issues for all involved. It also cannot easily be stored.

Machine Learning generates its own exhaust. 

The exhaust could be a positive feedback loop into the training data that, if it goes unnoticed, will poison predictions over time. 

The exhaust could be an absence of useable feedback. Any business that fits into a larger pipeline risks missing the piece of data that their models needs in order to learn. 

piece of The exhaust could be a high maintenance cost for a rare event.

  

is different for each situation, but suffice to say, . 

>  A shale natural gas industry requires an infrastructure that links up preexisting pressurized pipeline networks to preexisting points of demand. If you do not have that, you not only have to build it from scratch but build the actual demand from scratch as well.

> The same holds true for other types of infrastructure. Shale wells require hundreds of truck trips, and truck trips require, well, roads. Shale developments in virgin territory first require the development of a spiderweb of interconnected transport arteries.

> Put together these are exacting requirements. Few places in the world meet more than one of them, and only the United States has all of them.

  

  

#### Leveraging the Exhaust

  

  

Congrats, you got through it! The Accidental Superpower is a fascinating read and I highly recommend it. But don’t think I’m comparing oil to data or models to wells. If that were the case, natural gas wouldn’t make any sense. 

The point is that machine learning, like fracking, is an incredibly finicky technology. So finicky, it seems intended only to work for a certain environment. 

> It is extremely unlikely that the shale technologies will be applied en masse anywhere outside of North America before 2035.

>   

Some technologies, like cars, can be used anywhere. But are there are more rarefied technologies that require just the right geo-political conditions to take hold. Deep Sea Navigation, for example, transformed England and later Germany. But one analogy at a time.

In the case of fracking, North America maps to tech giants. You’ve got to have land to have oil, our users to have data. You’ve got to have deep pockets to take the risk. Most enterprise companies think of themselves of as data-driven, but the infrastructure really has to be in place. Most enterprise companies also think they have strong feedback loops, but not at the level of Facebook, Amazon or Google. Most enterprise companies are one small part in chain of transactions. That data is off-limits. 

Many startups won’t make it, unless they pay to drill on someone else’s land (See Rule 3: A Legal Structure That Rewards Landowners for Their Participation.)

Facebook, Amazon, & Google built their distribution platform a long time ago. They’re masters of 

And this goes a long way to explain the hype around machine learning. They’re excited about it because for them, its as obvious as water. 

  

  

  

It’s like David Foster Wallace’s joke about the fish…

To the tech giants, this is better water. 

  

  

The point is that machine learning is just as finicky as fracking. 

  

  

It isn’t a plug ’n’ play investment like javascript or SAP. 

  

  

I take this a few ways, so bare with me. 

In order for your company to take full advantage of machine learning, it must have a complimentary infrastructure. In this light, FANG, makes complete sense. They’ve each got scale. They’ve got vast wells of unique data. They have moats of ecosystems that support and rely on them (Arguably, this is where the landowner criteria could sort of fit). Most importantly, they have easy ways to test, deploy and feedback on models. 

  

  

In other words, the company has to already be set up in a way that compliments the dynamics of machine learning. Infrastructure not only means pipeline and long term commitment, but control over feedback loops. 

  

#### Only the USA

In the book, \_\_ makes the point that fracking was invention designed for what America already has in place. Ethics aside, this may be an incredibly efficient way to extract oil, but no other nation can take advantage of it.

#### FANG = USA

In this case, Facebook, Amazon, — -, already had the factors in place. Arguably they started out as AI companies. 

So they’re in a flywheel while everyone else is scratching rocks together to make a campfire.

I say this not to dissuade using ML, of course not. But instead of responding to the hype, get a better sense of your companies’ fitness for ML. 

For example, if you don’t have a centralized data warehouse, that should be your first priority. You may want your data to be flat. 

Invest in your developers by allowing them to explore the data without having to tie to a mission critical job. Remove some of the risk.

And look at new inputs, or sense organs. If you’re just expecting to dump to the same old data into a more powerful and expensive model, you may be underwhelmed with the results. 

But if you experimented with edge tech POCs, that could add a new dimension of insight, like fuel injection into your crusted data pipelines.

---

### notes

deep fried data also

Data is the new oil, a AI is the new fire. Sounds like a match made in heaven.

“AI is one of the most important things that humanity is working on. It’s more profound than, I don’t know, electricity or fire,” Google CEO Sundar Pichai

Andrew Ng often compares AI to electricity to explain how big of a deal this is. Sundar Pichai, Google’s CEO, went a step further to compare AI to fire. Given that everyone thinks that “data is the new oil,” this sounds like a match made in heaven. 

While Ng and Pichai are more qualified to speak about the manifest destiny of AI, there’s a lot of drama that’s going to happen before we get there. 

The truth is that some inventions only work at a certain scale. They only work if the all the environmental conditions are right.

Data is the decomposition of life. Data falls off us like skin cells. It’s swept up by sensors and dissected by spreadsheets. Machine learning lets scientists reconstitute the data into dioramas of our former selves.   
The phrase “data is the new oil” really captures our perceived value as phenomenological fossil fuel.
