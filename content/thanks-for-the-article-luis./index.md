---
title: "Thanks for the article, Luis."
description: "Alot of what you’re saying is right on."
date: "2019-08-05T02:26:08.507Z"
categories: []
published: false
---

Thanks for the article, Luis. I deal with these issues at an enterprise level, so I know what you’re talking about. 

Alot of what you’re saying is right on. 

We’ll think back on this time as the salad days of startups. Back when we owned the touchpoints, launched features, went viral.

We can imagine a future where our virtual assistant is the interface, gatekeeper and personalizer. If there are apps, they’ll be practically invisible, like APIs. 

While all that could be true, I think UX is just getting started. It’ll probably switch names a few times to keep the kids interested (AX, HCML, DMX), but there will always be **inputs and outputs**. 

AI takes data as an input and outputs results to the user. Even if the endpoints of the future converge into a singularity, what about the origin point? What about the data itself?

We’ve got more data than matter in the universe, but that tells us nothing about the value of the data. More data doesn’t always lead to better results.

There are plenty of cases of accidental racism spewing from AIs, so let’s look at a completely different example: the temperature.

  

 And if the framework which generates the data is biased, that data is dangerous. And if you think of data as bullets for a moment, we’re moving from pistols to machine guns. 

Data-hubris is just one of the problems we’ll encounter that is squarely in the domain of UX. (UX may not be directly attached to a product, it already seems to be drifting into ethics and politics.) But it’s going to require us to think very differently about experiences and interfaces. 

Think about the complexities of language. Meanings shift over time, phrases refer to themselves in illogical ways. There is no solving language.
